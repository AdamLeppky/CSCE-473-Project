{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nfrom random import shuffle\nimport torch\nfrom torch import nn\nimport math\nfrom glob import glob\nimport sys\nimport shutil  \n\n#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:45.771235Z","iopub.execute_input":"2022-05-31T14:41:45.771808Z","iopub.status.idle":"2022-05-31T14:41:47.553097Z","shell.execute_reply.started":"2022-05-31T14:41:45.771721Z","shell.execute_reply":"2022-05-31T14:41:47.552371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"../input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset\"\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:47.554852Z","iopub.execute_input":"2022-05-31T14:41:47.555324Z","iopub.status.idle":"2022-05-31T14:41:47.560434Z","shell.execute_reply.started":"2022-05-31T14:41:47.555288Z","shell.execute_reply":"2022-05-31T14:41:47.559704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport PIL\nimport random\nfrom scipy import ndimage\n\n\nclass segDataset(torch.utils.data.Dataset):\n    def __init__(self, root, training, transform=None):\n        super(segDataset, self).__init__()\n        self.root = root\n        self.training = training\n        self.transform = transform\n        self.IMG_NAMES = sorted(glob(self.root + '/*/images/*.jpg'))\n        self.BGR_classes = {'Water' : [ 41, 169, 226],\n                            'Land' : [246,  41, 132],\n                            'Road' : [228, 193, 110],\n                            'Building' : [152,  16,  60], \n                            'Vegetation' : [ 58, 221, 254],\n                            'Unlabeled' : [155, 155, 155]} # in BGR\n\n        self.bin_classes = ['Water', 'Land', 'Road', 'Building', 'Vegetation', 'Unlabeled']\n        \n    def __getitem__(self, idx):\n        img_path = self.IMG_NAMES[idx]\n        mask_path = img_path.replace('images', 'masks').replace('.jpg', '.png')\n\n        image = cv2.imread(img_path)\n        mask = cv2.imread(mask_path)\n        cls_mask = np.zeros(mask.shape)\n        cls_mask[mask == self.BGR_classes['Water']] = self.bin_classes.index('Water')\n        cls_mask[mask == self.BGR_classes['Land']] = self.bin_classes.index('Land')\n        cls_mask[mask == self.BGR_classes['Road']] = self.bin_classes.index('Road')\n        cls_mask[mask == self.BGR_classes['Building']] = self.bin_classes.index('Building')\n        cls_mask[mask == self.BGR_classes['Vegetation']] = self.bin_classes.index('Vegetation')\n        cls_mask[mask == self.BGR_classes['Unlabeled']] = self.bin_classes.index('Unlabeled')\n        cls_mask = cls_mask[:,:,0] \n        if self.training==True:\n            if self.transform:\n              image = transforms.functional.to_pil_image(image)\n              image = self.transform(image)\n              image = np.array(image)\n\n            # 90 degree rotation\n            if np.random.rand()<0.5:\n                angle = np.random.randint(4) * 90\n                image = ndimage.rotate(image,angle,reshape=True)\n                cls_mask = ndimage.rotate(cls_mask,angle,reshape=True)\n\n            # vertical flip\n            if np.random.rand()<0.5:\n                image = np.flip(image, 0)\n                cls_mask = np.flip(cls_mask, 0)\n            \n            # horizonal flip\n            if np.random.rand()<0.5:\n                image = np.flip(image, 1)\n                cls_mask = np.flip(cls_mask, 1)\n\n        image = cv2.resize(image, (512,512))/255.0\n        cls_mask = cv2.resize(cls_mask, (512,512)) \n        image = np.moveaxis(image, -1, 0)\n\n        return torch.tensor(image).float(), torch.tensor(cls_mask, dtype=torch.int64)\n\n\n    def __len__(self):\n        return len(self.IMG_NAMES)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:47.561804Z","iopub.execute_input":"2022-05-31T14:41:47.562079Z","iopub.status.idle":"2022-05-31T14:41:47.998666Z","shell.execute_reply.started":"2022-05-31T14:41:47.562042Z","shell.execute_reply":"2022-05-31T14:41:47.997958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_shift = transforms.ColorJitter(.1,.1,.1,.1)\nblurriness = transforms.GaussianBlur(3, sigma=(0.1, 2.0))\n\nt = transforms.Compose([color_shift, blurriness])\ndataset = segDataset('../input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset', training = True, transform= t)\n\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:48.002175Z","iopub.execute_input":"2022-05-31T14:41:48.002379Z","iopub.status.idle":"2022-05-31T14:41:48.070188Z","shell.execute_reply.started":"2022-05-31T14:41:48.002354Z","shell.execute_reply":"2022-05-31T14:41:48.069533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = dataset[1] ## __getitem__ is called\nplt.figure(figsize=(15,15))\nplt.subplot(1,2,1)\nplt.imshow(np.moveaxis(d[0].numpy(),0,-1))\nplt.subplot(1,2,2)\nplt.imshow(d[1].numpy())","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:48.072348Z","iopub.execute_input":"2022-05-31T14:41:48.072767Z","iopub.status.idle":"2022-05-31T14:41:49.336016Z","shell.execute_reply.started":"2022-05-31T14:41:48.072729Z","shell.execute_reply":"2022-05-31T14:41:49.335328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[1][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.336973Z","iopub.execute_input":"2022-05-31T14:41:49.337192Z","iopub.status.idle":"2022-05-31T14:41:49.816282Z","shell.execute_reply.started":"2022-05-31T14:41:49.337161Z","shell.execute_reply":"2022-05-31T14:41:49.815534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_num = int(0.1 * len(dataset))\nprint(f'test data : {test_num}')\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset)-test_num, test_num], generator=torch.Generator().manual_seed(101))\n\nBACH_SIZE = 4\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=BACH_SIZE, shuffle=True, num_workers=0)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=BACH_SIZE, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.817497Z","iopub.execute_input":"2022-05-31T14:41:49.817828Z","iopub.status.idle":"2022-05-31T14:41:49.82751Z","shell.execute_reply.started":"2022-05-31T14:41:49.81779Z","shell.execute_reply":"2022-05-31T14:41:49.826714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##################################### for GPU ###########################\n\ndef get_default_device():\n    # pick the gpu if available\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data,device):\n    #move tensors to choosen device\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device,non_blocking = True)\n\n\nclass DeviceDataLoader():\n    # move the batches of the data to our selected device\n    def __init__(self,dl,device):\n        self.dl = dl\n        self.device = device\n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    def __len__(self):\n        return len(self.dl)\n\ndevice = get_default_device()\n\ntrain_dataloader = DeviceDataLoader(train_dataloader, device)\ntest_dataloader = DeviceDataLoader(test_dataloader, device)\n\n#########################################################################","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.82944Z","iopub.execute_input":"2022-05-31T14:41:49.830031Z","iopub.status.idle":"2022-05-31T14:41:49.897354Z","shell.execute_reply.started":"2022-05-31T14:41:49.829985Z","shell.execute_reply":"2022-05-31T14:41:49.896408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.899005Z","iopub.execute_input":"2022-05-31T14:41:49.899339Z","iopub.status.idle":"2022-05-31T14:41:49.911769Z","shell.execute_reply.started":"2022-05-31T14:41:49.8993Z","shell.execute_reply":"2022-05-31T14:41:49.910166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.917673Z","iopub.execute_input":"2022-05-31T14:41:49.91813Z","iopub.status.idle":"2022-05-31T14:41:49.938473Z","shell.execute_reply.started":"2022-05-31T14:41:49.918081Z","shell.execute_reply":"2022-05-31T14:41:49.937464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.940077Z","iopub.execute_input":"2022-05-31T14:41:49.940398Z","iopub.status.idle":"2022-05-31T14:41:49.954246Z","shell.execute_reply.started":"2022-05-31T14:41:49.940357Z","shell.execute_reply":"2022-05-31T14:41:49.953332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, alpha=None, size_average=True):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.size_average = size_average\n\n    def forward(self, input, target):\n        if input.dim()>2:\n            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n        target = target.view(-1,1)\n\n        logpt = F.log_softmax(input, dim=-1)\n        logpt = logpt.gather(1,target)\n        logpt = logpt.view(-1)\n        pt = Variable(logpt.data.exp())\n\n        if self.alpha is not None:\n            if self.alpha.type()!=input.data.type():\n                self.alpha = self.alpha.type_as(input.data)\n            at = self.alpha.gather(0,target.data.view(-1))\n            logpt = logpt * Variable(at)\n\n        loss = -1 * (1-pt)**self.gamma * logpt\n        if self.size_average: return loss.mean()\n        else: return loss.sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.955917Z","iopub.execute_input":"2022-05-31T14:41:49.956456Z","iopub.status.idle":"2022-05-31T14:41:49.972717Z","shell.execute_reply.started":"2022-05-31T14:41:49.956412Z","shell.execute_reply":"2022-05-31T14:41:49.97193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = FocalLoss(gamma=3/4).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.976293Z","iopub.execute_input":"2022-05-31T14:41:49.976684Z","iopub.status.idle":"2022-05-31T14:41:49.985109Z","shell.execute_reply.started":"2022-05-31T14:41:49.976638Z","shell.execute_reply":"2022-05-31T14:41:49.984264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def acc(label, predicted):\n    seg_acc = (y.cpu() == torch.argmax(pred_mask, axis=1).cpu()).sum() / torch.numel(y.cpu())\n    return seg_acc\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.986447Z","iopub.execute_input":"2022-05-31T14:41:49.987197Z","iopub.status.idle":"2022-05-31T14:41:49.994929Z","shell.execute_reply.started":"2022-05-31T14:41:49.987156Z","shell.execute_reply":"2022-05-31T14:41:49.994166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_loss = torch.tensor(float('inf'))\n\nmodel = to_device(UNet(n_channels=3, n_classes=6, bilinear=True),device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:49.996436Z","iopub.execute_input":"2022-05-31T14:41:49.99674Z","iopub.status.idle":"2022-05-31T14:41:53.086413Z","shell.execute_reply.started":"2022-05-31T14:41:49.996704Z","shell.execute_reply":"2022-05-31T14:41:53.085607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:53.087835Z","iopub.execute_input":"2022-05-31T14:41:53.088085Z","iopub.status.idle":"2022-05-31T14:41:53.092611Z","shell.execute_reply.started":"2022-05-31T14:41:53.088052Z","shell.execute_reply":"2022-05-31T14:41:53.091846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./saved_models', exist_ok=True)\n\nN_EPOCHS = 50\nN_DATA = len(train_dataset)\nN_TEST = len(test_dataset)\n\nplot_losses = []\nscheduler_counter = 0","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:53.093906Z","iopub.execute_input":"2022-05-31T14:41:53.094517Z","iopub.status.idle":"2022-05-31T14:41:53.101729Z","shell.execute_reply.started":"2022-05-31T14:41:53.094479Z","shell.execute_reply":"2022-05-31T14:41:53.100941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total number of trainable parameters\npytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\npytorch_total_params","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:53.10368Z","iopub.execute_input":"2022-05-31T14:41:53.104448Z","iopub.status.idle":"2022-05-31T14:41:53.114008Z","shell.execute_reply.started":"2022-05-31T14:41:53.10441Z","shell.execute_reply":"2022-05-31T14:41:53.113274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(N_EPOCHS):\n  # training\n  model.train()\n  loss_list = []\n  acc_list = []\n  for batch_i, (x, y) in enumerate(train_dataloader):\n      pred_mask = model(x)  #[4,6,512,512]\n      loss = criterion(pred_mask, y)\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n      loss_list.append(loss.cpu().detach().numpy())\n      acc_list.append(acc(y,pred_mask).numpy())\n\n      sys.stdout.write(\n          \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f (%f)]\"\n          % (\n              epoch,\n              N_EPOCHS,\n              batch_i,\n              len(train_dataloader),\n              loss.cpu().detach().numpy(),\n              np.mean(loss_list),\n          )\n      )\n  scheduler_counter += 1\n  # testing\n  model.eval()\n  val_loss_list = []\n  val_acc_list = []\n  for batch_i, (x, y) in enumerate(test_dataloader):\n      with torch.no_grad():    \n          pred_mask = model(x)  \n      val_loss = criterion(pred_mask, y)\n      val_loss_list.append(val_loss.cpu().detach().numpy())\n      val_acc_list.append(acc(y,pred_mask).numpy())\n    \n  print(' epoch {} - loss : {:.5f} - acc : {:.2f} - val loss : {:.5f} - val acc : {:.2f}'.format(epoch, \n                                                                                                 np.mean(loss_list), \n                                                                                                 np.mean(acc_list), \n                                                                                                 np.mean(val_loss_list),\n                                                                                                 np.mean(val_acc_list)))\n  plot_losses.append([epoch, np.mean(loss_list), np.mean(val_loss_list)])\n\n  compare_loss = np.mean(val_loss_list)\n  is_best = compare_loss < min_loss\n  if is_best == True:\n    scheduler_counter = 0\n    min_loss = min(compare_loss, min_loss)\n    torch.save(model.state_dict(), './saved_models/unet_epoch_{}_{:.5f}.pt'.format(epoch,np.mean(val_loss_list)))\n  \n  if scheduler_counter > 5:\n    lr_scheduler.step()\n    print(f\"lowering learning rate to {optimizer.param_groups[0]['lr']}\")\n    scheduler_counter = 0\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T14:41:53.115506Z","iopub.execute_input":"2022-05-31T14:41:53.116157Z","iopub.status.idle":"2022-05-31T15:43:32.027895Z","shell.execute_reply.started":"2022-05-31T14:41:53.116109Z","shell.execute_reply":"2022-05-31T15:43:32.02713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot loss\nplot_losses = np.array(plot_losses)\nplt.plot(plot_losses[:,0], plot_losses[:,1], color='b', linewidth=4)\nplt.plot(plot_losses[:,0], plot_losses[:,2], color='r', linewidth=4)\nplt.title('FocalLoss', fontsize=20)\nplt.xlabel('epoch',fontsize=20)\nplt.ylabel('loss',fontsize=20)\nplt.grid()\nplt.legend(['training', 'validation']) # using a named size\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:32.029339Z","iopub.execute_input":"2022-05-31T15:43:32.029834Z","iopub.status.idle":"2022-05-31T15:43:32.2382Z","shell.execute_reply.started":"2022-05-31T15:43:32.029797Z","shell.execute_reply":"2022-05-31T15:43:32.237515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nfor batch_i, (x, y) in enumerate(test_dataloader):\n    for j in range(len(x)):\n        result = model(x[j:j+1])\n        mask = torch.argmax(result, axis=1).cpu().detach().numpy()[0]\n        im = np.moveaxis(x[j].cpu().detach().numpy(), 0, -1).copy()*255\n        im = im.astype(int)\n        gt_mask = y[j].cpu()\n\n        plt.figure(figsize=(12,12))\n\n        plt.subplot(1,3,1)\n        im = np.moveaxis(x[j].cpu().detach().numpy(), 0, -1).copy()*255\n        im = im.astype(int)\n        plt.imshow(im)\n\n        plt.subplot(1,3,2)\n        plt.imshow(gt_mask)\n\n        plt.subplot(1,3,3)\n        plt.imshow(mask)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:32.23956Z","iopub.execute_input":"2022-05-31T15:43:32.239837Z","iopub.status.idle":"2022-05-31T15:43:39.759399Z","shell.execute_reply.started":"2022-05-31T15:43:32.2398Z","shell.execute_reply":"2022-05-31T15:43:39.758711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision(y, pred_mask, classes = 6):\n    precision_list = [];\n    for i in range(classes):\n        actual_num = y.cpu() == i\n        predicted_num = i == torch.argmax(pred_mask, axis=1).cpu()\n        prec = torch.logical_and(actual_num,predicted_num).sum()/predicted_num.sum()\n        precision_list.append(prec.numpy().tolist())\n    return precision_list\n\ndef recall(y, pred_mask, classes = 6):\n    recall_list = []\n    for i in range(classes):\n        actual_num = y.cpu() == i\n        predicted_num = i == torch.argmax(pred_mask, axis=1).cpu()\n        recall_val = torch.logical_and(actual_num, predicted_num).sum() / actual_num.sum()\n        recall_list.append(recall_val.numpy().tolist())\n    return recall_list","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:39.760557Z","iopub.execute_input":"2022-05-31T15:43:39.760998Z","iopub.status.idle":"2022-05-31T15:43:39.770117Z","shell.execute_reply.started":"2022-05-31T15:43:39.76096Z","shell.execute_reply":"2022-05-31T15:43:39.769427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_list = []\nrecall_list = []\nfor batch_i, (x, y) in enumerate(test_dataloader):\n    for j in range(len(x)):\n        result = model(x[j:j+1])\n        precision_list.append(precision(y[j],result))\n        recall_list.append(recall(y[j],result))","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:39.771592Z","iopub.execute_input":"2022-05-31T15:43:39.772232Z","iopub.status.idle":"2022-05-31T15:43:46.632029Z","shell.execute_reply.started":"2022-05-31T15:43:39.772192Z","shell.execute_reply":"2022-05-31T15:43:46.631301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.nanmean(precision_list,axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:46.633279Z","iopub.execute_input":"2022-05-31T15:43:46.633535Z","iopub.status.idle":"2022-05-31T15:43:46.644198Z","shell.execute_reply.started":"2022-05-31T15:43:46.633501Z","shell.execute_reply":"2022-05-31T15:43:46.643035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.nanmean(recall_list,axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:46.645917Z","iopub.execute_input":"2022-05-31T15:43:46.647911Z","iopub.status.idle":"2022-05-31T15:43:46.654034Z","shell.execute_reply.started":"2022-05-31T15:43:46.647874Z","shell.execute_reply":"2022-05-31T15:43:46.653219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_precision = np.nanmean(precision_list,axis = 0)\nsum(final_precision[:-1])/5","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:46.65568Z","iopub.execute_input":"2022-05-31T15:43:46.656191Z","iopub.status.idle":"2022-05-31T15:43:46.668344Z","shell.execute_reply.started":"2022-05-31T15:43:46.65615Z","shell.execute_reply":"2022-05-31T15:43:46.667352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_recall = np.nanmean(recall_list,axis = 0)\nsum(final_recall)/5","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:46.669797Z","iopub.execute_input":"2022-05-31T15:43:46.670236Z","iopub.status.idle":"2022-05-31T15:43:46.68011Z","shell.execute_reply.started":"2022-05-31T15:43:46.670194Z","shell.execute_reply":"2022-05-31T15:43:46.679295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(),\"aerialImageSegmentation_using_U-net_and_ViT_100epochs\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T15:43:46.68431Z","iopub.execute_input":"2022-05-31T15:43:46.684539Z","iopub.status.idle":"2022-05-31T15:43:46.801352Z","shell.execute_reply.started":"2022-05-31T15:43:46.684511Z","shell.execute_reply":"2022-05-31T15:43:46.800573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}